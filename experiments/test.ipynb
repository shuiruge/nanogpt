{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250aebf8-3872-4ac5-ae23-a6beed98703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 14:33:53.157388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Layer, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import AdamW\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.utils import Progbar\n",
    "from nanogpt.utils import CharacterTokenizer, Embed, ResBlockWrapper, FeedForward, attention, MultiHeadWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f6f09f-948d-4430-90a2-ac20b2310ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you\n"
     ]
    }
   ],
   "source": [
    "with open('data/shakespeare.txt', 'r') as f:\n",
    "    corpus = ''.join(f.readlines())\n",
    "print(corpus[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563aecf0-7f80-4e8c-a130-57a8bcff1df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = CharacterTokenizer(corpus)\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a6d572-360e-40ed-9538-c0c16afdfe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8176289a-c1b7-4b09-a997-675eb899b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tmp.pkl', 'rb') as f:\n",
    "    contexts, targets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef7c94c-5397-4c9b-bb52-508094cfed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_data = len(corpus) - seq_len\n",
    "# contexts = []\n",
    "# targets = []\n",
    "# for i in range(n_data):\n",
    "#     context = tokenizer.encode(corpus[i:(i+seq_len)])\n",
    "#     target = tokenizer.encode(corpus[i+seq_len])[0]\n",
    "#     contexts.append(context)\n",
    "#     targets.append(target)\n",
    "# contexts = np.asarray(contexts, dtype='int32')\n",
    "# targets = np.asarray(targets, dtype='int32')\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('tmp.pkl', 'wb') as f:\n",
    "#     pickle.dump((contexts, targets), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "398ccfec-33fa-467b-afae-3f5a66df7996",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# contexts[0], targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c494a087-80a2-46de-8f16-79f1ae6e7879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullSelfAttention(Layer):\n",
    "    def __init__(self, model_dim, num_heads):\n",
    "        super().__init__()\n",
    "        self.model_dim = model_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.multihead = MultiHeadWrapper(self.num_heads)\n",
    "        self.attention_weights = None\n",
    "\n",
    "        self.get_key = Dense(model_dim)\n",
    "        self.get_value = Dense(model_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        query = self.multihead.split_heads(x)\n",
    "        key = self.multihead.split_heads(self.get_key(x))\n",
    "        value = self.multihead.split_heads(self.get_value(x))\n",
    "\n",
    "        output, attention_weights = attention(query, key, value)\n",
    "        output = self.multihead.concat_heads(output)\n",
    "        self.attention_weights = attention_weights\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e26b40f9-380f-4309-9e3a-37c8458ad0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGPT(Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, seq_len, embed_dim, model_dim, num_heads, ffd_dim, num_blocks):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_layers = [Embed(seq_len, seq_len, embed_dim)]\n",
    "        for i in range(num_blocks):\n",
    "            self.hidden_layers += [\n",
    "                ResBlockWrapper(FullSelfAttention(model_dim, num_heads)),\n",
    "                ResBlockWrapper(FeedForward([ffd_dim], model_dim)),\n",
    "            ]\n",
    "        self.output_layer = Dense(vocab_size)\n",
    "\n",
    "    def call(self, x):\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c963ba25-d689-48e5-a736-6ef1a38446ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_gpt_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embed_4 (Embed)             multiple                  12800     \n",
      "                                                                 \n",
      " res_block_wrapper_16 (ResB  multiple                  0 (unused)\n",
      " lockWrapper)                                                    \n",
      "                                                                 \n",
      " res_block_wrapper_17 (ResB  multiple                  0 (unused)\n",
      " lockWrapper)                                                    \n",
      "                                                                 \n",
      " res_block_wrapper_18 (ResB  multiple                  0 (unused)\n",
      " lockWrapper)                                                    \n",
      "                                                                 \n",
      " res_block_wrapper_19 (ResB  multiple                  0 (unused)\n",
      " lockWrapper)                                                    \n",
      "                                                                 \n",
      " dense_44 (Dense)            multiple                  4225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67329 (263.00 KB)\n",
      "Trainable params: 67329 (263.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyGPT(tokenizer.vocab_size, seq_len, 64, 64, 8, 128, 2)\n",
    "model.build([None, seq_len])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "129f1cce-c536-452d-8cfe-3b2303de497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 14:38:37.436332: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 446117600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3075/34853 [=>............................] - ETA: 31:53 - loss: 2.3592"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/engine/training.py:1789\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1787\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1788\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1789\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/callbacks.py:1155\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Updates the progbar.\"\"\"\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m logs \u001b[38;5;241m=\u001b[39m logs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m-> 1155\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_init_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_steps:\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m=\u001b[39m batch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/callbacks.py:1130\u001b[0m, in \u001b[0;36mProgbarLogger._maybe_init_progbar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics)\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel:\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;66;03m# Update the existing stateful metrics as `self.model.metrics` may\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# contain updated metrics after `MetricsContainer` is built in the\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;66;03m# first train step.\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics\u001b[38;5;241m.\u001b[39munion(\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28mset\u001b[39m(m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m)\n\u001b[1;32m   1131\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar \u001b[38;5;241m=\u001b[39m Progbar(\n\u001b[1;32m   1135\u001b[0m         target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget,\n\u001b[1;32m   1136\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1137\u001b[0m         stateful_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstateful_metrics,\n\u001b[1;32m   1138\u001b[0m         unit_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_steps \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1139\u001b[0m     )\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/engine/training.py:916\u001b[0m, in \u001b[0;36mModel.metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m         metrics \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiled_metrics\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_layers():\n\u001b[1;32m    917\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mextend(l\u001b[38;5;241m.\u001b[39m_metrics)\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m metrics\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/engine/base_layer.py:3306\u001b[0m, in \u001b[0;36mLayer._flatten_layers\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   3305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flatten_layers\u001b[39m(\u001b[38;5;28mself\u001b[39m, recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, include_self\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 3306\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flatten_modules(\n\u001b[1;32m   3307\u001b[0m         recursive\u001b[38;5;241m=\u001b[39mrecursive, include_self\u001b[38;5;241m=\u001b[39minclude_self\n\u001b[1;32m   3308\u001b[0m     ):\n\u001b[1;32m   3309\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, Layer):\n\u001b[1;32m   3310\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m m\n",
      "File \u001b[0;32m/nix/store/4iz1prnx8i6i06l941hpjwgs0a45c87s-python3.11-keras-2.14.0/lib/python3.11/site-packages/keras/src/engine/base_layer.py:3335\u001b[0m, in \u001b[0;36mLayer._flatten_modules\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   3333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trackable_id \u001b[38;5;129;01min\u001b[39;00m seen_object_ids:\n\u001b[1;32m   3334\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3335\u001b[0m seen_object_ids\u001b[38;5;241m.\u001b[39madd(trackable_id)\n\u001b[1;32m   3337\u001b[0m \u001b[38;5;66;03m# Metrics are not considered part of the Layer's topology.\u001b[39;00m\n\u001b[1;32m   3338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(trackable_obj, tf\u001b[38;5;241m.\u001b[39mModule) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3339\u001b[0m     trackable_obj, metrics_mod\u001b[38;5;241m.\u001b[39mMetric\n\u001b[1;32m   3340\u001b[0m ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True))\n",
    "model.fit(contexts, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7023903-b3c1-4d20-9b3d-6d2a251d8de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d625809-7809-49fe-94ce-20128b66c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_step(model, optimizer, loss):\n",
    "    step = tf.Variable(0, dtype=tf.int64, trainable=False)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x)\n",
    "            loss_value = tf.reduce_mean(loss(y, y_pred))\n",
    "        grads = tape.gradient(loss_value, model.weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.weights))\n",
    "        step.assign_add(1)\n",
    "        return loss_value\n",
    "\n",
    "    return train_step, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2ef6c-6f16-4927-b401-fa74c5065e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step, step = get_train_step(model, AdamW(), SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240ceaf-c162-4be8-98ca-85d5a4b97723",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((contexts, targets))\n",
    "ds = ds.batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484443d3-0375-4964-8ad8-28689ebf5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_bar = Progbar(len(ds))\n",
    "for x, y in ds:\n",
    "    loss_value = train_step(x, y)\n",
    "    process_bar.update(current=tf.cast(step, tf.float32), values=[('loss', loss_value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba47f5-48b1-405a-a1a8-389152524623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
